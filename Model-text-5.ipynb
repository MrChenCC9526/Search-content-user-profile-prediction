{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import config # 自定义配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\11147\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 导入自定义模块\n",
    "sys.path.append(config.Py_path) # 添加路径\n",
    "from SaveAndLoad import save_pkl,load_pkl # 数据文件持久化与加载\n",
    "from BuildModel import get_train_test,BF_nn_Model\n",
    "from ModelEvaluation import nnModel_ACC,Model_ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DF数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(config.AF_Data_path + \"AFAfter.csv\")\n",
    "col_list = [\"Education\",\"age\",\"gender\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词向量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载TFIDF词向量数据\n",
    "TFIDF_sp = load_pkl(\"TFIDF_sp\")\n",
    "TFIDF_HW_sp = load_pkl(\"TFIDF_HW_sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载W2V词向量数据\n",
    "W2V_X_sp = load_pkl(\"W2V_X_sp\")\n",
    "W2V_HW_sp = load_pkl(\"W2V_HW_sp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_Model = DBSCAN(\n",
    "        eps=0.5,  # 邻域的距离阈值ϵ\\epsilon\n",
    "        min_samples=5,  # 核心对象所需要的邻域的样本数阈值\n",
    "        metric='euclidean', # 度量方式;欧氏距离\n",
    "        algorithm='auto',  # 近邻算法求解方式;auto为自动选择\n",
    "#         leaf_size=30,  # 近邻算法求解方式\n",
    "        n_jobs=6 # CPU并行数\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CLUSTER = DB_Model.fit_predict(TFIDF_sp.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_Model.labels_ # 分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_Model_2 = DBSCAN(\n",
    "        eps=0.5,  # 邻域的距离阈值ϵ\\epsilon\n",
    "        min_samples=5,  # 核心对象所需要的邻域的样本数阈值\n",
    "        metric='euclidean', # 度量方式;欧氏距离\n",
    "        algorithm='auto',  # 近邻算法求解方式;auto为自动选择\n",
    "#         leaf_size=30,  # 近邻算法求解方式\n",
    "        n_jobs=6 # CPU并行数\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., -1,  0, -1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_CLUSTER_2 = DB_Model_2.fit_predict(W2V_X_sp)\n",
    "DB_CLUSTER_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1     10148\n",
       " 0      7386\n",
       " 10       14\n",
       " 9        11\n",
       " 8        10\n",
       " 12        7\n",
       " 7         7\n",
       " 6         7\n",
       " 5         7\n",
       " 16        7\n",
       " 17        6\n",
       " 13        5\n",
       " 11        5\n",
       " 14        5\n",
       " 4         5\n",
       " 3         5\n",
       " 1         5\n",
       " 18        5\n",
       " 15        3\n",
       " 2         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(DB_CLUSTER_2).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0],\n",
       "       [ 0],\n",
       "       [ 0],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [ 0],\n",
       "       [-1]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_CLUSTER_2.reshape((DB_CLUSTER_2.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17651, 101)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((W2V_X_sp, DB_CLUSTER_2.reshape((DB_CLUSTER_2.shape[0], 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, Y_tr, Y_te = get_train_test(np.hstack((W2V_X_sp, DB_CLUSTER_2.reshape((DB_CLUSTER_2.shape[0], 1)))),data[\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.python.keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot编码\n",
    "y_train = np_utils.to_categorical(Y_tr)\n",
    "y_test = np_utils.to_categorical(Y_te)\n",
    "\n",
    "num_class = len(Y_tr.value_counts())  # 计算目标列类别数量\n",
    "input_num = X_tr.shape[1]  # 输入层尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型各层的参数状况\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 300)               30600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 2107      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 32,707\n",
      "Trainable params: 32,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()  # 实例化\n",
    "# 输入层\n",
    "model.add(Dense(300, input_shape=(input_num,)))  # 全连接层\n",
    "\n",
    "# 隐含层\n",
    "model.add(Dropout(0.3))  # 随机失活\n",
    "model.add(Activation('tanh'))  # 激活函数,tanh\n",
    "model.add(Dense(y_train.shape[1]))  # 全连接层\n",
    "\n",
    "# 输出层\n",
    "model.add(Activation('softmax'))  # 激活函数,softmax\n",
    "\n",
    "# 配置训练方法\n",
    "model.compile(loss='categorical_crossentropy',  # 损失函数，分类交叉熵\n",
    "              optimizer='adadelta',  # 优化器，自适应增量 Adaptive Delta\n",
    "              metrics=['accuracy'])  # 准确率评测，精确度\n",
    "\n",
    "print(\"模型各层的参数状况\")\n",
    "print(model.summary())  # 查看模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 早停\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor = 'val_loss',\n",
    "                          mode='min',\n",
    "                          min_delta = 0.01,\n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 早停并保存最优模型\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "mc_earlystop = ModelCheckpoint(filepath=config.Model_path + \"text_model.h5\",\n",
    "                     monitor='val_loss',\n",
    "                     mode='max',\n",
    "                     verbose=1,\n",
    "                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12355 samples, validate on 5296 samples\n",
      "Epoch 1/100\n",
      "12355/12355 [==============================] - 0s 29us/step - loss: 1.2736 - acc: 0.4743 - val_loss: 1.1762 - val_acc: 0.5102\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.17624, saving model to ./Model/text_model.h5\n",
      "Epoch 2/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1750 - acc: 0.5099 - val_loss: 1.1609 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.17624\n",
      "Epoch 3/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.1482 - acc: 0.5259 - val_loss: 1.1412 - val_acc: 0.5378\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.17624\n",
      "Epoch 4/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1348 - acc: 0.5324 - val_loss: 1.1408 - val_acc: 0.5179\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.17624\n",
      "Epoch 5/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1302 - acc: 0.5352 - val_loss: 1.1509 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.17624\n",
      "Epoch 6/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1245 - acc: 0.5420 - val_loss: 1.1181 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.17624\n",
      "Epoch 7/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1221 - acc: 0.5451 - val_loss: 1.1061 - val_acc: 0.5544\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.17624\n",
      "Epoch 8/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.1134 - acc: 0.5474 - val_loss: 1.1223 - val_acc: 0.5591\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.17624\n",
      "Epoch 9/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1134 - acc: 0.5442 - val_loss: 1.1095 - val_acc: 0.5523\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.17624\n",
      "Epoch 10/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1089 - acc: 0.5505 - val_loss: 1.1436 - val_acc: 0.5191\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.17624\n",
      "Epoch 11/100\n",
      "12355/12355 [==============================] - 0s 14us/step - loss: 1.1081 - acc: 0.5505 - val_loss: 1.1189 - val_acc: 0.5393\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.17624\n",
      "Epoch 12/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.1049 - acc: 0.5536 - val_loss: 1.1092 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.17624\n",
      "Epoch 13/100\n",
      "12355/12355 [==============================] - 0s 15us/step - loss: 1.1070 - acc: 0.5522 - val_loss: 1.1085 - val_acc: 0.5617\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.17624\n",
      "Epoch 14/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.1040 - acc: 0.5565 - val_loss: 1.1435 - val_acc: 0.5211\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.17624\n",
      "Epoch 15/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.1012 - acc: 0.5540 - val_loss: 1.0988 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.17624\n",
      "Epoch 16/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1027 - acc: 0.5515 - val_loss: 1.1387 - val_acc: 0.5380\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.17624\n",
      "Epoch 17/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.1024 - acc: 0.5493 - val_loss: 1.1212 - val_acc: 0.5432\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.17624\n",
      "Epoch 18/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0982 - acc: 0.5514 - val_loss: 1.0996 - val_acc: 0.5670\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.17624\n",
      "Epoch 19/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0965 - acc: 0.5585 - val_loss: 1.1166 - val_acc: 0.5517\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.17624\n",
      "Epoch 20/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0976 - acc: 0.5609 - val_loss: 1.1053 - val_acc: 0.5617\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.17624\n",
      "Epoch 21/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0970 - acc: 0.5545 - val_loss: 1.0977 - val_acc: 0.5621\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.17624\n",
      "Epoch 22/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0962 - acc: 0.5565 - val_loss: 1.1281 - val_acc: 0.5449\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.17624\n",
      "Epoch 23/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0976 - acc: 0.5599 - val_loss: 1.1177 - val_acc: 0.5498\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.17624\n",
      "Epoch 24/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0948 - acc: 0.5561 - val_loss: 1.0992 - val_acc: 0.5572\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.17624\n",
      "Epoch 25/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0944 - acc: 0.5561 - val_loss: 1.1201 - val_acc: 0.5608\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.17624\n",
      "Epoch 26/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0938 - acc: 0.5596 - val_loss: 1.1231 - val_acc: 0.5281\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.17624\n",
      "Epoch 27/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0916 - acc: 0.5600 - val_loss: 1.1238 - val_acc: 0.5336\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.17624\n",
      "Epoch 28/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0903 - acc: 0.5575 - val_loss: 1.1397 - val_acc: 0.5279\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.17624\n",
      "Epoch 29/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0909 - acc: 0.5608 - val_loss: 1.0982 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.17624\n",
      "Epoch 30/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0917 - acc: 0.5565 - val_loss: 1.1073 - val_acc: 0.5423\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.17624\n",
      "Epoch 31/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0908 - acc: 0.5587 - val_loss: 1.1042 - val_acc: 0.5529\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.17624\n",
      "Epoch 32/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0900 - acc: 0.5583 - val_loss: 1.0979 - val_acc: 0.5604\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.17624\n",
      "Epoch 33/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0888 - acc: 0.5643 - val_loss: 1.0942 - val_acc: 0.5623\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.17624\n",
      "Epoch 34/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0902 - acc: 0.5599 - val_loss: 1.1369 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.17624\n",
      "Epoch 35/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0887 - acc: 0.5568 - val_loss: 1.1126 - val_acc: 0.5493\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.17624\n",
      "Epoch 36/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0887 - acc: 0.5583 - val_loss: 1.1139 - val_acc: 0.5423\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.17624\n",
      "Epoch 37/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0902 - acc: 0.5587 - val_loss: 1.1031 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.17624\n",
      "Epoch 38/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0871 - acc: 0.5609 - val_loss: 1.1036 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.17624\n",
      "Epoch 39/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0854 - acc: 0.5620 - val_loss: 1.0965 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.17624\n",
      "Epoch 40/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0839 - acc: 0.5611 - val_loss: 1.0996 - val_acc: 0.5619\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.17624\n",
      "Epoch 41/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0888 - acc: 0.5591 - val_loss: 1.0975 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.17624\n",
      "Epoch 42/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0842 - acc: 0.5585 - val_loss: 1.1001 - val_acc: 0.5565\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.17624\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0845 - acc: 0.5655 - val_loss: 1.1000 - val_acc: 0.5578\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.17624\n",
      "Epoch 44/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0821 - acc: 0.5596 - val_loss: 1.0936 - val_acc: 0.5661\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.17624\n",
      "Epoch 45/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0867 - acc: 0.5630 - val_loss: 1.1018 - val_acc: 0.5527\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.17624\n",
      "Epoch 46/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0835 - acc: 0.5631 - val_loss: 1.0939 - val_acc: 0.5665\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.17624\n",
      "Epoch 47/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0858 - acc: 0.5632 - val_loss: 1.1027 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.17624\n",
      "Epoch 48/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0855 - acc: 0.5622 - val_loss: 1.0975 - val_acc: 0.5646\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.17624\n",
      "Epoch 49/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0837 - acc: 0.5595 - val_loss: 1.1026 - val_acc: 0.5638\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.17624\n",
      "Epoch 50/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0829 - acc: 0.5617 - val_loss: 1.1100 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.17624\n",
      "Epoch 51/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0864 - acc: 0.5601 - val_loss: 1.1087 - val_acc: 0.5514\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.17624\n",
      "Epoch 52/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0844 - acc: 0.5610 - val_loss: 1.0954 - val_acc: 0.5610\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.17624\n",
      "Epoch 53/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0795 - acc: 0.5633 - val_loss: 1.1104 - val_acc: 0.5476\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.17624\n",
      "Epoch 54/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0860 - acc: 0.5590 - val_loss: 1.1000 - val_acc: 0.5582\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.17624\n",
      "Epoch 55/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0820 - acc: 0.5619 - val_loss: 1.0984 - val_acc: 0.5608\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.17624\n",
      "Epoch 56/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0792 - acc: 0.5605 - val_loss: 1.1097 - val_acc: 0.5412\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.17624\n",
      "Epoch 57/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0810 - acc: 0.5621 - val_loss: 1.0949 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.17624\n",
      "Epoch 58/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0801 - acc: 0.5638 - val_loss: 1.0919 - val_acc: 0.5701\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.17624\n",
      "Epoch 59/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0802 - acc: 0.5620 - val_loss: 1.0975 - val_acc: 0.5612\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.17624\n",
      "Epoch 60/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0789 - acc: 0.5640 - val_loss: 1.0924 - val_acc: 0.5659\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.17624\n",
      "Epoch 61/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0802 - acc: 0.5655 - val_loss: 1.0903 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.17624\n",
      "Epoch 62/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0794 - acc: 0.5615 - val_loss: 1.1035 - val_acc: 0.5517\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.17624\n",
      "Epoch 63/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0801 - acc: 0.5635 - val_loss: 1.1031 - val_acc: 0.5578\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.17624\n",
      "Epoch 64/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0814 - acc: 0.5636 - val_loss: 1.0947 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.17624\n",
      "Epoch 65/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0803 - acc: 0.5633 - val_loss: 1.0886 - val_acc: 0.5704\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.17624\n",
      "Epoch 66/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0785 - acc: 0.5637 - val_loss: 1.1311 - val_acc: 0.5363\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.17624\n",
      "Epoch 67/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0775 - acc: 0.5600 - val_loss: 1.1093 - val_acc: 0.5610\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.17624\n",
      "Epoch 68/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0767 - acc: 0.5633 - val_loss: 1.1161 - val_acc: 0.5423\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.17624\n",
      "Epoch 69/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0811 - acc: 0.5582 - val_loss: 1.1029 - val_acc: 0.5614\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.17624\n",
      "Epoch 70/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0766 - acc: 0.5643 - val_loss: 1.0977 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.17624\n",
      "Epoch 71/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0773 - acc: 0.5631 - val_loss: 1.0998 - val_acc: 0.5551\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.17624\n",
      "Epoch 72/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0782 - acc: 0.5638 - val_loss: 1.1111 - val_acc: 0.5408\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.17624\n",
      "Epoch 73/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0771 - acc: 0.5645 - val_loss: 1.0884 - val_acc: 0.5663\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.17624\n",
      "Epoch 74/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0759 - acc: 0.5601 - val_loss: 1.1060 - val_acc: 0.5480\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.17624\n",
      "Epoch 75/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0766 - acc: 0.5624 - val_loss: 1.0869 - val_acc: 0.5655\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.17624\n",
      "Epoch 76/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0744 - acc: 0.5658 - val_loss: 1.1021 - val_acc: 0.5648\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.17624\n",
      "Epoch 77/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0730 - acc: 0.5660 - val_loss: 1.0880 - val_acc: 0.5689\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.17624\n",
      "Epoch 78/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0752 - acc: 0.5607 - val_loss: 1.0945 - val_acc: 0.5589\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.17624\n",
      "Epoch 79/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0756 - acc: 0.5637 - val_loss: 1.1084 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.17624\n",
      "Epoch 80/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0749 - acc: 0.5606 - val_loss: 1.0927 - val_acc: 0.5631\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.17624\n",
      "Epoch 81/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0750 - acc: 0.5647 - val_loss: 1.0946 - val_acc: 0.5629\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.17624\n",
      "Epoch 82/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0741 - acc: 0.5657 - val_loss: 1.1004 - val_acc: 0.5536\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.17624\n",
      "Epoch 83/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0733 - acc: 0.5668 - val_loss: 1.0906 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.17624\n",
      "Epoch 84/100\n",
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0746 - acc: 0.5634 - val_loss: 1.0885 - val_acc: 0.5682\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.17624\n",
      "Epoch 85/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0721 - acc: 0.5674 - val_loss: 1.0946 - val_acc: 0.5616\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.17624\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12355/12355 [==============================] - 0s 13us/step - loss: 1.0731 - acc: 0.5662 - val_loss: 1.0902 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.17624\n",
      "Epoch 87/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0740 - acc: 0.5630 - val_loss: 1.1175 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.17624\n",
      "Epoch 88/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0729 - acc: 0.5645 - val_loss: 1.0877 - val_acc: 0.5642\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.17624\n",
      "Epoch 89/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0706 - acc: 0.5664 - val_loss: 1.1099 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.17624\n",
      "Epoch 90/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0719 - acc: 0.5665 - val_loss: 1.0908 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 1.17624\n",
      "Epoch 91/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0697 - acc: 0.5656 - val_loss: 1.0970 - val_acc: 0.5602\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.17624\n",
      "Epoch 92/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0719 - acc: 0.5675 - val_loss: 1.1037 - val_acc: 0.5599\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.17624\n",
      "Epoch 93/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0738 - acc: 0.5623 - val_loss: 1.0932 - val_acc: 0.5642\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.17624\n",
      "Epoch 94/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0714 - acc: 0.5659 - val_loss: 1.0881 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.17624\n",
      "Epoch 95/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0709 - acc: 0.5706 - val_loss: 1.0901 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.17624\n",
      "Epoch 96/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0702 - acc: 0.5694 - val_loss: 1.0865 - val_acc: 0.5651\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.17624\n",
      "Epoch 97/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0714 - acc: 0.5643 - val_loss: 1.0923 - val_acc: 0.5657\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.17624\n",
      "Epoch 98/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0681 - acc: 0.5667 - val_loss: 1.1018 - val_acc: 0.5642\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.17624\n",
      "Epoch 99/100\n",
      "12355/12355 [==============================] - 0s 12us/step - loss: 1.0687 - acc: 0.5654 - val_loss: 1.0892 - val_acc: 0.5697\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 1.17624\n",
      "Epoch 100/100\n",
      "12355/12355 [==============================] - 0s 11us/step - loss: 1.0696 - acc: 0.5657 - val_loss: 1.0984 - val_acc: 0.5657\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.17624\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "history = model.fit(\n",
    "    X_tr, y_train,  # XY\n",
    "    # verbose=2,  # 0 为不在标准输出流输出日志信息；1 为输出进度条记录；2 没有进度条，只是输出一行记录\n",
    "    epochs=100,  # 训练次数,训练模型的迭代数\n",
    "    batch_size=128, # 批处理大小,每次梯度更新的样本数\n",
    "    validation_data=(X_te, y_test),  # 验证数据\n",
    "    shuffle=True,  # 在每个epoch之前对训练数据进行洗牌\n",
    "    callbacks = [mc_earlystop], # 早停\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.5658, 测试集准确度: 0.5657\n"
     ]
    }
   ],
   "source": [
    "# 计算模型准确度\n",
    "model_pred_tr,model_pred_te = nnModel_ACC(model,X_tr, X_te, Y_tr, Y_te,ReYN = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.5723, 测试集准确度: 0.5712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "LR_model.fit(model_pred_tr,Y_tr)\n",
    "\n",
    "Model_ACC(LR_model,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.5759, 测试集准确度: 0.5689\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# 模型实例化\n",
    "clf = svm.SVC(probability=True)\n",
    "\n",
    "clf.fit(model_pred_tr,Y_tr) # 模型训练\n",
    "\n",
    "Model_ACC(clf,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:59] WARNING: D:\\Build\\xgboost\\xgboost-1.3.1.git\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "XGB_Model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "Y_tr[Y_tr==6] = 0\n",
    "Y_te[Y_te==6] = 0\n",
    "\n",
    "XGB_Model = XGB_Model.fit(model_pred_tr,Y_tr)\n",
    "XGB_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.8376, 测试集准确度: 0.5508\n"
     ]
    }
   ],
   "source": [
    "Model_ACC(XGB_Model,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.5733, 测试集准确度: 0.5674\n",
      "训练集准确度: 0.5733, 测试集准确度: 0.5638\n",
      "训练集准确度: 0.5732, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5732, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5732, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5633\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5657\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5657\n",
      "训练集准确度: 0.5735, 测试集准确度: 0.5646\n",
      "训练集准确度: 0.5730, 测试集准确度: 0.5657\n"
     ]
    }
   ],
   "source": [
    "for Mnum in range(350,410,5):\n",
    "    Tr_Model = DecisionTreeClassifier(criterion='entropy',min_samples_leaf=Mnum,max_depth=500)\n",
    "    Tr_Model.fit(model_pred_tr,Y_tr)\n",
    "    Model_ACC(Tr_Model,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_Model = DecisionTreeClassifier(criterion='gini',min_samples_leaf=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(min_samples_leaf=30)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tr_Model.fit(model_pred_tr,Y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度: 0.8323, 测试集准确度: 0.8121\n"
     ]
    }
   ],
   "source": [
    "Model_ACC(Tr_Model,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:06:41] WARNING: D:\\Build\\xgboost\\xgboost-1.3.1.git\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:06:54] WARNING: D:\\Build\\xgboost\\xgboost-1.3.1.git\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "训练集准确度: 0.8376, 测试集准确度: 0.5508\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "STKC = StackingClassifier(classifiers=[LR_model, clf, XGB_Model],\n",
    "                          use_probas=False, # 类别概率值作为meta-classfier的输入\n",
    "                          average_probas=False,  # 是否对每一个类别产生的概率值做平均\n",
    "                          meta_classifier=xgb.XGBClassifier(use_label_encoder=False))\n",
    "\n",
    "STKC.fit(model_pred_tr,Y_tr)\n",
    "\n",
    "Model_ACC(STKC,model_pred_tr, model_pred_te, Y_tr, Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
